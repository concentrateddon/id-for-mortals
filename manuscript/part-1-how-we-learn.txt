# Part 1: How We Learn #
Understanding how human brains learn is the key to helping them do it better and more easily. In this part, I'll break down some of the yawn-inducing cognitive science into something a bit jazzier and real-world.

# Why do We Learn?
The first thing we need to think about is why human brains learn at all. Plenty of creatures on this planet _don't_ learn; they respond instinctively do specific stimuli, and there's not much you can do to change that. But for creatures that can learn, and can change their behaviors based on what they learn, there's really only a one reason why:

It helps them survive. 

Alligators will "learn" that humans are food providers if humans feed the alligator (sometimes just one feeding will do the trick). Being alligators, they don't always differentiate between "humans bring food" and "humans are food," but you know. Alligators. The point is that most learning, at a very basic biological level, is possible because it's what helps us survive in this cold, cruel world of ours. Brains developed the ability to remember things, and to connect those memories to scenarios, and to process those scenarios, because doing so helps us live longer. 

That's why so much instructional design is focused on engaging natural human survival instincts. It's a big part of why the "problem-solution" approach works so well for humans. If our brains can be made to understand that a problem exists, then our brains will seek a solution to that problem. If a solution can then be provided, our brains will tend to lock on to that more readily.

Of course, learning is a lot more complex than just "let's try to outlive the next guy," but our _ability_ to learn is rooted in that age-old desire to survive.

# What is Learning?
Now we should probably decide what _learning_ even means. A gent named Benjamin Bloom, back in the 1950s, came up with a taxonomy for learning, and it remains a useful way to talk about what learning really is. He defined several different _kinds_ of learning, and ranked them from fairly easy and low level, up to harder and more high level.

He started with *Remembering*. Basic memorization, in other words. Humans do okay at this. In the brain, memories are formed by connections between neurons. The more neurons that get connected, the stronger and clearer the memory is, and the easier it is to recall. There are a few ways that our brains create stronger memories, and the most basic of those is _repetition_. Forcing us to recall something over and over and over will, over time, create a stronger memory. Memorizing the multiplication tables in school is a great example of this: there's no obvious connection between 3x4 and survival, but the rote memorization process takes advantage of our brains' ability to reinforce memory strength with repetition. That ability is itself a survival mechanism, helping ensure that the most often-encountered facts and memories are available for rapid recall should we need them.

Bloom then moves on to _Comprehension_. This is different than mere remembering; I remember that DNA stands for deoxyribonucleic acid, but I honestly couldn't tell you what that word _means_. Comprehension is when you've remembered something, but also know what it means. You can organize, compare, interpret, explain, and re-state things that you comprehend. I comprehend how a gasoline engine works at a basic level, and I can explain it to you.

Up next is _Applying_. Having come to understand something, you can start applying that something in new situations. You can solve problems, and identify relationships between things. I comprehend how electrical circuits work, and I can apply that comprehension to create new kinds of electrical circuits to solve for specific problems.

Next is _Analyzing_. Once you're able to apply something, you can start breaking it down into its component parts, figure out how those parts relate to each other, and make inferences for new knowledge. Because I understand how oranges help support a healthy diet, I can start to analyze other foods for similarities, and create theories about what other foods might similarly support a heathy diet.

Let's pause for a moment, and think about things you've learned in the past. Too often, formal education often focuses on remembering, asking us to memorize facts but not even worrying if we comprehend them. Comprehension is hard to test, whereas the ability to spit back facts is pretty easy to test. And if testing someone's comprehension is hard, imaging how hard it is to test if someone can perform analysis! But obviously, simply _knowing_ something isn't where most of us want to stop learning. We should want to _understand_ it, and be able to _use_ it in real-world situations. 

* This berry is poisonous. 
* This berry contains poisons, which when ingested may kill me.
* This berry might kill other forms of life, too. I could maybe kill predators with it.
* If this berry kills, then other plants might also kill. There is probably a family of foods that can kill.
* If I can isolate the commonalities between foods that kill, I may be able to isolate the killing substances, and either neutralize them or harvest them specifically.

That last step is _Synthesizing,_ the next step up Bloom's taxonomy. It's the ability to take lots of things that you've analyzed and start building models or discerning patterns.

Finally, there's _Evaluating_. This is the ability to take everything that's come before, and present and defend opinions. You make judgements about information you have, the validity of ideas you're presented with, and so on, based on various criteria. I think we can all agree that, objectively, lots and lots of human beings don't do any kind of evaluating. The need for a site like Snopes.com (which attempts to verify or dispel urban myths), and the frequency with which known-to-be-false stories spread on social media, proves that evaluating is a rarified atmosphere. Evaluation asks us to _question_, and to start from the presumption that whatever we're presented is neither correct nor incorrect, but must instead be proven to be one or the other. That's _hard_, and it creates the possibility for conflict, which most people avoid, because conflict "hurts" and we instinctively tend to avoid things that hurt.

Before you set out to teach anything, you need to decide what level you're trying to achieve. Asking someone to memorize something is easy; explaining it so that they comprehend what they've memorized is similarly straightforward. Helping them learn to apply their new knowledge can be straightforward, too, especially if you're able to present realistic scenarios as you teach. 

Moving through to analysis gets tough. Analysis takes a kind of leap, and it often requires a very broad base of learning. Teaching someone how to add and subtract numbers isn't hard; teaching them how a checking account works isn't hard. Teaching someone to balance a checkbook is, on the whole, not terribly hard. Teaching someone to analyze their budget is a big next step. Moving through to synthesis and evaluation is harder yet, because they each require an exponentially larger knowledge base to work from. Those last three — analysis, synthesis, and evaluation — are also like muscles in that, if you never use them, they don't really develop. Kids who aren't taught to question things and to evaluate proofs grow up into adults who often _can't_ do those things.

So for better or for worse, most educators tend to aim for application-level learning: knowing facts, understanding them, and being able to apply them in the real world. It's the nature of our brains that make those the low-hanging fruit of education. My point here is that you need to know where you're aiming, instructionally, in order to get there; if you do indeed have a goal of moving someone into those higher three cognitive levels, you need to aim very hard, and very carefully, because they're difficult targets to hit.

# Making Memories
The basis of all learning is, of course, _memory_, which is why Remembering sits at the base of Bloom's Taxonomy. So how do memories actually get made in the human brain?

There are three broad areas of the brain that are relevant to memory. The entorhinal cortex, a thin outer layer of tissue, acts as a kind of active filter for incoming content. It's what helps us focus, and choose what to ignore and what to pay attention to. The hippocampus is where memory formation begins, and for those memories the brain decides to keep, the neocortex gets involved to actually store them.

Physically, memories are linked groups of brain cells called _neurons_. When a memory is accessed, that entire group of neurons electrically "fire" at once, recreating sensations, knowledge, and so on. In many cases, the neurons that "store" a memory are the same ones that initially "fired" when we experienced whatever it was for the first time. So by and large, the neurons that "lit up" the first time you tasted chocolate are the same ones "lighting up" right now as you read these words, letting you experience some of that flavor again without actually eating any. The connections between neurons, called _synapses_, actually get thicker the more you use them - almost like a callous building up on skin that's exposed to repeated friction. Thicker synapses are stronger, more readily accessible memories because they can more easily transmit electricity between the neurons they connect.

Memory recall is a tricky beast. It's not at all like opening a file on your computer and reading it, although that's an analogy that springs easily to most people's minds. No, for us, _remembering_ is more like asking the brain to photocopy a memory onto a piece of transparent plastic. We then take that plastic, scribble on it, and re-file it on top of the original memory. The very act of remembering can change the underlying memory, which is why police detectives are so cautious about eyewitness reports. 

As an instructional designer, this really creates two important takeaways: first, repetition can be an important learning tools, and second, guided repetition can help cement a memory _correctly_ without our brains trying to "tweak" the memory. Another takeaway comes from that entorhinal cortex, which actively filters what we're perceiving and potentially remembering: we need to "break through" learners' filters, and make a memory _important_ to them, or it won't "stick." And we need to do that judiciously, because brains simply aren't designed to remember every little thing. Imagine if yours tried to actively remember every teensy little detail of your daily life! You'd be awash in mostly useless memories, and rapidly find yourself unable to function.

Numerous studies — and I won't bore you with the cognitive science details here, but you'll find them in the Additional Reading section at the end of this book — have defined some limits on how much new information the average brain can assimilate in a given sitting, and about how many hours a single learning session can practically last. We know that there's a _forgetting curve_ of sorts, a span of time over which new memories are likely to become less strong. However, we also know that letting a memory fade a bit, before later reinforcing it, can actually create a stronger memory in the end game. There's a definite science to memory, and it forms the basis of some of the guidelines I'll introduce you to later.

The way the brain stores memories also gives us a clue for how to make better memories more quickly. A single memory isn't just one neuron floating alone in our gray matter; it's a bunch of them, all connected in a network via synapses. _Connected_. Our brains are story makers, and they seek patterns and relationships automatically. New information is more likely to be retained if it can immediately connect to an existing network of neurons, especially ones that already have strong, thick synaptic connections. This is the power of analogies, where we take something already familiar to the learner, and adroitly connect something new to it. Imagine that you need to hang a new piece of art — are you more likely to be successful hanging it on an existing, sturdy wall, or attempting to hang it on a recently-strung sheet of paper?

Current cognitive science suggests that all memories have two "strengths:" a storage strength, and a retrieval strength. Storage strength is simply a measure of how well we learned something, and we can increase that through repetition and by actually using the memory. Storage strength, the theory goes, can grow, but never decrease. We never _lose_ memories, although they may, through disuse, become disconnected from the neurons we _do_ use, making those memories essentially irretrievable. That's the retrieval strength: a measure of how easily a memory can be brought to mind. This also increases with use, but it drops of rapidly if the memory isn't being used. So while our brains are in theory full of everything we've ever learned, we really can only access a subset of it any any given moment. Retrieval strength rebuilds quickly, though. For a memory with a strong storage strength, a quick reminder can often bring it back to full, roaring life after years of disuse. 

So: as instructional designers, we want to help our learners build memories that have a high storage strength, and as much as possible connect them to existing, strong memories. That provides the best chance for a high retrieval strength, or at least the ability to quickly re-build retrieval strength in the future. 

But first we need to break through that damn entorhinal cortex.

# Cracking the Filter
There are a couple of reasons kids learn more readily than adults. One is simple survival: in a rush to not wind up on some apex predator's plate, younger brains rapidly absorb everything they can and start constructing stories. But another reason is the world a kid lives in. It's relatively less "full" than an adult's world, meaning the entorhinal cortex doesn't need to filter stuff quite so aggressively. We tend to put kids into formal learning environments that actively minimize distractions. As adults, though, we've got to get through our morning commute, worry about the bills, keep junior's soccer schedule in mind, and do our actual day-to-day job. Our filters kick in hardcore. Never forget that the job of the brain filter is _beneficial_, because if we let our brains start forming high-strength memories out of everything we experience, we'd quickly lose the ability to navigate our own memories. It's not that our brains would "fill up," it's that the slightest provocation would retrieve far more memories than we'd be able to deal with. Our filters are designed to _protect_ us, by not creating strong memories out of anything not deemed important right then.

Learning, then, requires us to make a strong enough case to those filters to let strong new memories be created. It's a bit like auditioning for a television competition like _American Idol_. Before you get in front of the four main judges and a TV camera, you first have to get through the phalanx of interns in several phases of screening. They're the filters, making sure that the "real" judges only get the best of the best (and the occasional too-bad-to-be-true performer, just to keep the viewers engaged). So if we're going to create strong new memories in our learners, we've got to put on our best singing voice and really impress those interns.

Brains, for better or for worse, are biased. Tell a Pepsi lover that you're going to discuss the health advantages of Coke, and you've already lost half the battle. So you have to start by finding common ground with your learners, and that's often done through storytelling. By casting them in the central role of your narrative, and by starting the story at a time and place they're already familiar with, you engage the brain's biases, rather than working against them. This is nominally why instructors are advised to go 'round the room on the first day of class and "do introductions." You're meant to get a feel for where your learners are starting, so that you can frame your story appropriately. 

Familiar analogies are another way to break the filter. When you start with what is obviously a story of sorts, you're setting the filter at ease. "I clearly don't need to remember this," the filter says, as it relaxes and grabs a glass of water. If your analogy invokes existing memories in learners, firing up existing neurons, the filter can remain relaxed. If you then add a bit of information to that existing neural network, just tacking on a small new neuron or two to the existing collection, the filter's less likely to sit up and take notice. This is just a new coloring on existing information. If that existing information already had a strong synaptic network, then it's already been deemed "important," and so attaching new information won't raise any red flags. In this way, we can sneak new bits into the brain, bypassing the filter.

The point here is that, for adult learners, _you need to clearly make the incoming information relevant to them_ or their filter will just try to block it all out. We'll look at several techniques for doing so, but keep in mind that the whole reason behind it all is to get that filter's permission to start creating new memories.

# Memory to Application
So how does the brain move from mere memorization through comprehension and into application, and how can we as instructional designers assist it on that journey?

Let's first address what cognitive science people mean by _application_. I've worked for years in the technology industry, and "training classes" often consist of a lecture, which is meant to cover the operational theory and "why" of a technology, followed by hands-on labs. These labs are _meant_ to reinforce the lecture, and to create a stronger memory by having the learner actually use what they've just learned. But too often, these labs are basically long, numbered lists of _exactly_ what to do. This is literally _training_, in the way that you'd train a dog or a dolphin; it's not _application_. Learners aren't being taught something and then tossed out on their own to start using it; there's no actual cognitive connection between the lecture and the lists of tasks you can simply follow _without thinking about it_. These types of classes often skip the _comprehension_ step, and without comprehension, there can be no true application.

Comprehension happens when the brain can bring together multiple pieces of information that it has memorized, and start relating those pieces of information to each other. Comprehension is understanding the _why_ of a topic, and that often requires a broader set of background information. For the human brain, comprehension usually requires us to have a story, of sorts, around the topic that we're learning. That story helps us draw all of the necessary facts together into a sort of pattern, or narrative. With comprehension, we're not just reciting facts we've memorized; we're able to place those facts into a sensible context.

**A key indicator for comprehension is a learner's ability to restate the topic in their own words, explaining it to someone else, and to ideally be able to create their own analogies to explain that topic.**

To aid the learner in achieving true comprehension, we need to go beyond just teaching them some end fact that we want them to know. It's not enough to say, "the US Constitution was created over the course of several months in the 1770s, and was largely a compromise between various different political goals held by the delegates to the Constitutional Congress." That's a fact, but it doesn't get into the details of those compromises, those varying political goals, or any of the other context of the situation. To really get a learner to _comprehend_ that topic, we'd need to spend a lot more time providing historical context, relevant anecdotes, and so on. Achieving comprehension _takes a lot more time_ than simply teaching facts, and it's one reason that we, as instructional designers, start to become constrained in how much we can actually teach in a given period of time.

Moving learners to _application_ level learning takes even more time. To continue with the Constitutional example, we'd want learners to be able to suggest changes that they might make if the Constitution had to be rewritten from scratch. Not changes to the text, but changes to the process that we'd just taught them about. We'd ask them to identify "holes" in the narrative we'd taught, getting them to look for missing facts. Getting a learner to that point involves a lot more discussion, and an even broader background of information to work from.

To switch to a somewhat simpler analogy, let's say that I, as an instructional designer, was asked to design some instructional tool that taught you, the learner, how to build a cabinet with shelves and drawers.

* If my goal was simply to achieve remembering, then I'd give you precise plans, some basic information on the tools required, and call it a day. You'd only be able to build the exact cabinet I gave you plans for, though.
* If my goal was to achieve comprehension, then I'd have to do a little more work to explain the engineering that goes into a cabinet. How wide can a shelf or drawer be? How much weight can they bear? How might different joining techniques increase strength or stability? This would enable you to more fully understand _why_ cabinets are built like they are, and explain the process to someone else.
* If my goal was to achieve application, then I'd likely go even deeper into the engineering and possible variations. We might discuss the different kinds of materials involved, for example, and I'd want you to be able to build cabinets for a variety of situations.

_Training_, again in the sense of what you'd do with a dog or a dolphin, often requires little more than remembering. But to make a human being self-sufficient in a task, you need to move them through to application. They need to be able to perform a task on their own, with little guidance, and deal with at least common variations or alternate scenarios.

None of this is impossible, but far too often instructional designers set out with an arbitrary list of things they want to teach in a given period of time, and don't think about how heavy a burden they're taking on if actual comprehension and application is the goal. 

And let's be clear: sometimes, remembering _is all you need to achieve_. When I worked on F-14 Tomcat jets, we had a big room filled with manuals on how to put one together. Like, literally hundreds of manuals for every possible part and system on the aircraft. These were mainly step-by-step task lists, and provided you had a basic understanding of how to use the tools involved, you could probably get the job done. You'd never know _why_ that particular kind of bolt was used in that particular spot, and you'd never be able to make any kind of substitutions, but that wasn't the goal. As a mechanic, I didn't _need_ to know, and I wasn't _allowed_ to make any alternate decisions, and so simply _remembering_ the steps involved was sufficient. And, because the manuals were largely designed to remember _for me_, very little teaching was, in theory, required.

My education on F-14s actually _did_ go further. I had plenty of classroom time to learn the theory of operation — the "why" and "when" — of the aircraft. The intent was to take me through comprehension and into some degree of application so that, in theory, I could work on a battle-damaged aircraft and make decisions about how to get it in the air quickly, if not optimally. That education took _time_, though. Four years of it, to be precise; if all the Navy had wanted was a monkey to put the planes together, they probably could have accomplished that in four months or less. Every step of the cognitive ladder takes an exponentially longer amount of time to accomplish.




